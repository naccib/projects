from subject import Subject, SubjectCollection
from typing import List
from random import choices

import pandas as pd

import numpy as np
import pandas as pd

from scipy.ndimage.filters import gaussian_filter


VERBOSE = True
LOG = lambda s: print(f"[AUG] {s}") if VERBOSE else None


"""
Augmentation techniques to be used:
 1. Gaussian filter
 2. Scale
 3. Flips

 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5977656/pdf/2730723.pdf)
"""

def gaussian(image: np.ndarray) -> np.ndarray:
    return image

def scale(image: np.ndarray) -> np.ndarray:
    return image

def flip(image: np.ndarray) -> np.ndarray:
    return image


OP_LIST = (
    gaussian,
    scale,
    flip
)


def augment(subjects: SubjectCollection, class_balancing = True, count_multiplier = 1.0) -> List[np.ndarray]:
    """
    Augments the `subjects` list.

    If `class_balancing` is `True`, the classes will be
    balanced as a first step of augmentation.

    `count_multiplier` specifies the amount of new data
    that will be generated by multiplying the initial
    data count.

    Note that all subjects that were not augmented
    will remain as a `Nifti2Image`, not a `np.ndarray`.
    This is done in an effort to reduce memory consumption.
    """

    if class_balancing:
        LOG("Balancing classes...")

        subjects = balance_classes(subjects, subjects.metada)

    LOG("All the subjects that were not augmented will remain as a `Nifti2Image`.")
    LOG("Make sure to call get_data on them or `utils.flatten_subjects`  to retrieve the `np.ndarray`.")

    return subjects


def balance_classes(subjects: SubjectCollection, metadata: pd.DataFrame) -> List[np.ndarray]:
    (s_count, c_count) = group_count(metadata)

    LOG(f"Initial (schz, control): {s_count}, {c_count}")

    if s_count == c_count:
        # classes are balanced
        LOG("Classes are already balanced. Aborting balancing.")

        return subjects

    delta = abs(s_count - c_count)
    op_map = operation_map(delta)

    diagnosis = 'CONTROL' if s_count > c_count else 'SCHZ'

    LOG(f"Generating {delta} more {diagnosis}")
    
    sample = [subj for subj in subjects.subjects if subj.diagnosis == diagnosis]
    sample = choices(sample, k=delta)

    # From now on, we will use raw data only
    subjects = [subj.load_anat('space-MNI152NLin2009cAsym_preproc') for subj in subjects.subjects]

    for i in range(0, delta):
        operation = op_map[i]

        image = sample[i].load_anat('space-MNI152NLin2009cAsym_preproc').get_data()
        image = OP_LIST[operation](image)

        sample[i] = image

    return subjects + sample
    

def operation_map(length: int) -> np.ndarray:
    """
    Generates a operation map with length `length`.

    A operation map is a integer array where each
    number (0, 1, 2) represents a different operation.

    This map is randomly ordered and uniformly distributed.
    """

    return np.random.randint(0, 3, length, dtype=np.int8)


def group_count(metadata: pd.DataFrame) -> (int, int):
    """
    Returns the counts of schizophrenics and controls
    in the given subjects `metadata`.
    """

    schz = metadata[metadata['diagnosis'] == 'SCHZ']
    control = metadata[metadata['diagnosis'] == 'CONTROL']

    return (len(schz), len(control))